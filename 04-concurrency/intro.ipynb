{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] [Concurrency](https://en.wikipedia.org/wiki/Concurrency_(computer_science)) in Python\n",
    "Concurrency is the action of running several tasks at the time (concurrently). Notice that concurrency does not means [paralelism](https://en.wikipedia.org/wiki/Parallel_computing) (only one task can be running while the rest wait)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU-bound and I/O-bound problems\n",
    "IO-bound programs need to stop waiting for IO transactions. In this context, concurrency is used to switch to a different trask, expecting that will not have the same problem.\n",
    "\n",
    "CPU-bound programs, on the flip size, are those that does not need to wait for IO operations and keep the CPU working all the time (in fact, the spped of the code is limited by the CPU). In the ideal case, using N identical CPUs it is expected to divide by N the running time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concurrency solutions in Python\n",
    "\n",
    "Python provides 3 alternatives for running more than one task concurrently:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Threads](https://docs.python.org/3/library/threading.html)\n",
    "\n",
    "A [thread](https://en.wikipedia.org/wiki/Thread_(computing)) is a sequence of instructions that periodically are executed, typically, in concurrency (and somethimes, depending on the computing context, in parallel) with other threads [of the same process space](https://pymotw.com/3/threading/index.html#module-threading). However, you must know that [CPU-bound tasks are not a good fit for Python threads, due to the Global Interpreter Lock (GIL). Parallel computations in Python should be done in multiple processes, not threads.](http://eli.thegreenplace.net/2011/12/27/python-threads-communication-and-stopping) As a consequence of this problem, at this moment, it is impossible to use more than one [CPU](https://en.wikipedia.org/wiki/Central_processing_unit) using Python Threads in [CPython](https://en.wikipedia.org/wiki/CPython), exclusively.\n",
    "\n",
    "Concurrency based on threads is also called *Pre-emptive multitasking*.\n",
    "\n",
    "In Python, threads are useful to solve IO-bound problems, where the resource that is limiting the speed of your code is an IO device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Processes](https://docs.python.org/3/library/multiprocessing.html)\n",
    "\n",
    "[Processes](https://en.wikipedia.org/wiki/Process_%28computing%29) allow the parallel execution of code in [multiprocessing systems](https://en.wikipedia.org/wiki/Multiprocessing). This can be used to solve the previously mentioned limitation of the GIL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Coroutines](https://docs.python.org/3/library/asyncio-task.html#coroutines)\n",
    "\n",
    "A [coroutine](https://en.wikipedia.org/wiki/Coroutine) is a function that voluntarly gives the CPU control (*yield*s) to a different corutine (by referencing it). Corutines remember their running context when they resume. Coroutines are also named cooperative tasks, and therefore, concurrency based on coroutines is also called *cooperative multitasking*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use them (specially, in Python)\n",
    "In general, threads and processes are useful when the problem to solve has blocking instructions (basically, it uses I/O operations that waits for a data transference completion, such as the incomming of a packet from a socket). Coroutines are interesting when the user explicitly specify the points in the code where the execution must be transfered between tasks (coroutines)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads vs coroutines in Python\n",
    "In Python, the GIL only allows to run one thread at the same time. Moreover, the OS overhead produced by the thread random and fine-grain switching between threads is higher than the negligible overhead generated by the coroutines. Therefore, when the problem is divided into subtasks (coroutines) and there is a dependence between them (some must wait for data the the others provide), coroutines are more efficient. Amother advantage of coroutines is that it is not necessary to have support from the OS to implement concurrency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happen with the process space\n",
    "Threads and coroutines share the same process space (the same segments of memory), and therefore is trivial to share data between threads and coroutines. However, processes by definition does not share their process spaces. To overcome this pitfall, the Python Librabry provides data sharing solution between processes that are run in the same Python module. In any case, interprocess communications are slower and more difficult to implement that their thread/coroutines versions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
